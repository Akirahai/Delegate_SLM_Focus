{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dcfe8db",
   "metadata": {},
   "source": [
    "# Set up Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206b4d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/long/miniconda3/envs/delegate/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, time, torch\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, function_tool, ModelSettings\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from utils import extracted_box, len_extract_boxed\n",
    "from grader import math_equal\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18592fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, InputGuardrail, GuardrailFunctionOutput, Runner\n",
    "from agents.exceptions import InputGuardrailTripwireTriggered\n",
    "from pydantic import BaseModel\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e860731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.shared.reasoning import Reasoning\n",
    "\n",
    "from agents import Agent, ModelSettings, Runner, trace\n",
    "from agents.items import ReasoningItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fe7606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "MODEL = \"gemini/gemini-2.5-flash\"\n",
    "GPUS=\"0 5\"\n",
    "SAMPLES=10\n",
    "SEED=0\n",
    "DATASET=\"math_500\"\n",
    "MAX_TOKENS=8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab0b45c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54a38fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(current_dir).parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "276d8b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/long/miniconda3/envs/delegate/lib/python310.zip',\n",
       " '/data/long/miniconda3/envs/delegate/lib/python3.10',\n",
       " '/data/long/miniconda3/envs/delegate/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/data/long/miniconda3/envs/delegate/lib/python3.10/site-packages',\n",
       " '/data/long/hai/Individual_Project/Delegate_SLM_Focus/experiments',\n",
       " '/tmp/tmpwswdq2no',\n",
       " '/data/long/hai/Individual_Project/Delegate_SLM_Focus']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools.data_loader import read_data\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce193c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 problems from GSM8K (test split)\n"
     ]
    }
   ],
   "source": [
    "test_df = read_data(DATASET, n_samples=SAMPLES, random_seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d88c89",
   "metadata": {},
   "source": [
    "# Host and Request Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=7 vllm serve Qwen/Qwen2.5-1.5B-Instruct \\\n",
    "#   --tensor-parallel-size 1 \\\n",
    "#   --gpu-memory-utilization 0.9 \\\n",
    "#   --enable-auto-tool-choice \\\n",
    "#   --tool-call-parser hermes \\\n",
    "#   --reasoning-parser deepseek_r1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=6,7 vllm serve Qwen/Qwen2.5-Math-1.5B-Instruct --tensor-parallel-size 2 --gpu-memory-utilization 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=7 vllm serve Qwen/Qwen2.5-1.5B-Instruct --tensor-parallel-size 1 --gpu-memory-utilization 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153df33",
   "metadata": {},
   "source": [
    "## Request Model (normal Framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "164fd6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Response:\n",
      "\n",
      "Here's a haiku about loving:\n",
      "\n",
      "**Warmth spreads through the quiet,  \n",
      "A steady hand, a gentle voice—  \n",
      "Heart finds its true home.**\n",
      "\n",
      "*   **Line 1 (5 syllables):** Establishes the feeling of deep, quiet love (\"Warmth spreads through the quiet\").\n",
      "*   **Line 2 (7 syllables):** Shows the actions and presence of love (\"A steady hand, a gentle voice\").\n",
      "*   **Line 3 (5 syllables):** Conveys the ultimate, fulfilling destination of love (\"Heart finds its true home\").\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# === Configuration ===\n",
    "BASE_URL = \"http://localhost:8000/v1\"\n",
    "MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"  # or \"Qwen3-4B\" if you used --served-model-name\n",
    "\n",
    "# === Send request ===\n",
    "payload = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku for me about loving.\"}\n",
    "    ],\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/chat/completions\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    data=json.dumps(payload)\n",
    ")\n",
    "\n",
    "# === Display result ===\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"✅ Response:\\n\")\n",
    "    print(data[\"choices\"][0][\"message\"][\"content\"])\n",
    "else:\n",
    "    print(f\"❌ Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "434ffd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-b187d3b2ebcd4b1cb6d9e17bddc06f95',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1762947653,\n",
       " 'model': 'Qwen/Qwen3-4B-Instruct-2507',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'Here\\'s a haiku about loving:\\n\\n**Warmth spreads through the quiet,  \\nA steady hand, a gentle voice—  \\nHeart finds its true home.**\\n\\n*   **Line 1 (5 syllables):** Establishes the feeling of deep, quiet love (\"Warmth spreads through the quiet\").\\n*   **Line 2 (7 syllables):** Shows the actions and presence of love (\"A steady hand, a gentle voice\").\\n*   **Line 3 (5 syllables):** Conveys the ultimate, fulfilling destination of love (\"Heart finds its true home\").',\n",
       "    'refusal': None,\n",
       "    'annotations': None,\n",
       "    'audio': None,\n",
       "    'function_call': None,\n",
       "    'tool_calls': [],\n",
       "    'reasoning_content': None},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop',\n",
       "   'stop_reason': None,\n",
       "   'token_ids': None}],\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'prompt_tokens': 29,\n",
       "  'total_tokens': 148,\n",
       "  'completion_tokens': 119,\n",
       "  'prompt_tokens_details': None},\n",
       " 'prompt_logprobs': None,\n",
       " 'prompt_token_ids': None,\n",
       " 'kv_transfer_params': None}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a191b834",
   "metadata": {},
   "source": [
    "## Agents SDK Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae22bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"\"\"\n",
    "You are a math calculator. Put the final answer in \\\\boxed{} at the end.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ed0a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"Math Router\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=LitellmModel(model=\"hosted_vllm/Qwen/Qwen3-4B-Instruct-2507\", base_url=\"http://localhost:8000/v1\"),\n",
    "    model_settings=ModelSettings(\n",
    "        max_tokens=1024,\n",
    "        parallel_tool_calls=False,\n",
    "        reasoning={\"effort\": \"low\"},\n",
    "        include_usage=True,\n",
    "    ),\n",
    "    # tools=[slm_help],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7235fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await Runner.run(agent, test_df.iloc[2]['problem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b146756c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunResult(input='What is $\\\\left(4\\\\dfrac{5}{8}\\\\right)^{55} \\\\cdot \\\\left(\\\\dfrac{8}{37}\\\\right)^{55}$?', new_items=[MessageOutputItem(agent=Agent(name='Math Router', handoff_description=None, tools=[], mcp_servers=[], mcp_config={}, instructions='\\nYou are a math calculator. Put the final answer in \\\\boxed{} at the end.\\n', prompt=None, handoffs=[], model=<agents.extensions.models.litellm_model.LitellmModel object at 0x7f549f88f4c0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=1024, reasoning=Reasoning(effort='low', generate_summary=None, summary=None), verbosity=None, metadata=None, store=None, include_usage=True, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='We are given the expression:\\n\\n$$\\n\\\\left(4\\\\dfrac{5}{8}\\\\right)^{55} \\\\cdot \\\\left(\\\\dfrac{8}{37}\\\\right)^{55}\\n$$\\n\\n---\\n\\n### Step 1: Convert the mixed number to an improper fraction\\n\\n$$\\n4\\\\dfrac{5}{8} = \\\\dfrac{4 \\\\times 8 + 5}{8} = \\\\dfrac{32 + 5}{8} = \\\\dfrac{37}{8}\\n$$\\n\\nSo the expression becomes:\\n\\n$$\\n\\\\left(\\\\dfrac{37}{8}\\\\right)^{55} \\\\cdot \\\\left(\\\\dfrac{8}{37}\\\\right)^{55}\\n$$\\n\\n---\\n\\n### Step 2: Use the property of exponents: $ a^n \\\\cdot b^n = (a \\\\cdot b)^n $\\n\\n$$\\n\\\\left(\\\\dfrac{37}{8} \\\\cdot \\\\dfrac{8}{37}\\\\right)^{55}\\n$$\\n\\nNow simplify the product inside the parentheses:\\n\\n$$\\n\\\\dfrac{37}{8} \\\\cdot \\\\dfrac{8}{37} = \\\\dfrac{37 \\\\cdot 8}{8 \\\\cdot 37} = 1\\n$$\\n\\nSo the expression becomes:\\n\\n$$\\n1^{55} = 1\\n$$\\n\\n---\\n\\n### ✅ Final Answer:\\n\\n$$\\n\\\\boxed{1}\\n$$', type='output_text', logprobs=None)], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='We are given the expression:\\n\\n$$\\n\\\\left(4\\\\dfrac{5}{8}\\\\right)^{55} \\\\cdot \\\\left(\\\\dfrac{8}{37}\\\\right)^{55}\\n$$\\n\\n---\\n\\n### Step 1: Convert the mixed number to an improper fraction\\n\\n$$\\n4\\\\dfrac{5}{8} = \\\\dfrac{4 \\\\times 8 + 5}{8} = \\\\dfrac{32 + 5}{8} = \\\\dfrac{37}{8}\\n$$\\n\\nSo the expression becomes:\\n\\n$$\\n\\\\left(\\\\dfrac{37}{8}\\\\right)^{55} \\\\cdot \\\\left(\\\\dfrac{8}{37}\\\\right)^{55}\\n$$\\n\\n---\\n\\n### Step 2: Use the property of exponents: $ a^n \\\\cdot b^n = (a \\\\cdot b)^n $\\n\\n$$\\n\\\\left(\\\\dfrac{37}{8} \\\\cdot \\\\dfrac{8}{37}\\\\right)^{55}\\n$$\\n\\nNow simplify the product inside the parentheses:\\n\\n$$\\n\\\\dfrac{37}{8} \\\\cdot \\\\dfrac{8}{37} = \\\\dfrac{37 \\\\cdot 8}{8 \\\\cdot 37} = 1\\n$$\\n\\nSo the expression becomes:\\n\\n$$\\n1^{55} = 1\\n$$\\n\\n---\\n\\n### ✅ Final Answer:\\n\\n$$\\n\\\\boxed{1}\\n$$', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=70, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=306, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=376), response_id=None)], final_output='We are given the expression:\\n\\n$$\\n\\\\left(4\\\\dfrac{5}{8}\\\\right)^{55} \\\\cdot \\\\left(\\\\dfrac{8}{37}\\\\right)^{55}\\n$$\\n\\n---\\n\\n### Step 1: Convert the mixed number to an improper fraction\\n\\n$$\\n4\\\\dfrac{5}{8} = \\\\dfrac{4 \\\\times 8 + 5}{8} = \\\\dfrac{32 + 5}{8} = \\\\dfrac{37}{8}\\n$$\\n\\nSo the expression becomes:\\n\\n$$\\n\\\\left(\\\\dfrac{37}{8}\\\\right)^{55} \\\\cdot \\\\left(\\\\dfrac{8}{37}\\\\right)^{55}\\n$$\\n\\n---\\n\\n### Step 2: Use the property of exponents: $ a^n \\\\cdot b^n = (a \\\\cdot b)^n $\\n\\n$$\\n\\\\left(\\\\dfrac{37}{8} \\\\cdot \\\\dfrac{8}{37}\\\\right)^{55}\\n$$\\n\\nNow simplify the product inside the parentheses:\\n\\n$$\\n\\\\dfrac{37}{8} \\\\cdot \\\\dfrac{8}{37} = \\\\dfrac{37 \\\\cdot 8}{8 \\\\cdot 37} = 1\\n$$\\n\\nSo the expression becomes:\\n\\n$$\\n1^{55} = 1\\n$$\\n\\n---\\n\\n### ✅ Final Answer:\\n\\n$$\\n\\\\boxed{1}\\n$$', input_guardrail_results=[], output_guardrail_results=[], tool_input_guardrail_results=[], tool_output_guardrail_results=[], context_wrapper=RunContextWrapper(context=None, usage=Usage(requests=1, input_tokens=70, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=306, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=376)), _last_agent=Agent(name='Math Router', handoff_description=None, tools=[], mcp_servers=[], mcp_config={}, instructions='\\nYou are a math calculator. Put the final answer in \\\\boxed{} at the end.\\n', prompt=None, handoffs=[], model=<agents.extensions.models.litellm_model.LitellmModel object at 0x7f549f88f4c0>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=1024, reasoning=Reasoning(effort='low', generate_summary=None, summary=None), verbosity=None, metadata=None, store=None, include_usage=True, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "899f972d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are given the expression:\n",
      "\n",
      "$$\n",
      "\\left(4\\dfrac{5}{8}\\right)^{55} \\cdot \\left(\\dfrac{8}{37}\\right)^{55}\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Convert the mixed number to an improper fraction\n",
      "\n",
      "$$\n",
      "4\\dfrac{5}{8} = \\dfrac{4 \\times 8 + 5}{8} = \\dfrac{32 + 5}{8} = \\dfrac{37}{8}\n",
      "$$\n",
      "\n",
      "So the expression becomes:\n",
      "\n",
      "$$\n",
      "\\left(\\dfrac{37}{8}\\right)^{55} \\cdot \\left(\\dfrac{8}{37}\\right)^{55}\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "### Step 2: Use the property of exponents: $ a^n \\cdot b^n = (a \\cdot b)^n $\n",
      "\n",
      "$$\n",
      "\\left(\\dfrac{37}{8} \\cdot \\dfrac{8}{37}\\right)^{55}\n",
      "$$\n",
      "\n",
      "Now simplify the product inside the parentheses:\n",
      "\n",
      "$$\n",
      "\\dfrac{37}{8} \\cdot \\dfrac{8}{37} = \\dfrac{37 \\cdot 8}{8 \\cdot 37} = 1\n",
      "$$\n",
      "\n",
      "So the expression becomes:\n",
      "\n",
      "$$\n",
      "1^{55} = 1\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "### ✅ Final Answer:\n",
      "\n",
      "$$\n",
      "\\boxed{1}\n",
      "$$\n"
     ]
    }
   ],
   "source": [
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47848535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: 70\n",
      "Output tokens: 306\n",
      "Total tokens: 376\n",
      "Reasoning tokens: 0\n",
      "Cached tokens: 0\n",
      "--------------------------------------------------------------------------------\n",
      "The final result is:\n"
     ]
    }
   ],
   "source": [
    "response = result.raw_responses[0]\n",
    "print(\"Input tokens:\", response.usage.input_tokens)\n",
    "print(\"Output tokens:\", response.usage.output_tokens)\n",
    "print(\"Total tokens:\", response.usage.total_tokens)\n",
    "# Access detailed breakdown\n",
    "print(\"Reasoning tokens:\", response.usage.output_tokens_details.reasoning_tokens)\n",
    "print(\"Cached tokens:\", response.usage.input_tokens_details.cached_tokens)\n",
    "\n",
    "\n",
    "# Output Results\n",
    "print(\"-\"*80)\n",
    "print(\"The final result is:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delegate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
